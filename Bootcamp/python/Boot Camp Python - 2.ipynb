{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Research Computing Bootcamp\n",
    "# Boston University\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website: [rcs.bu.edu](http://www.bu.edu/tech/support/research/) <br>\n",
    "Tutorial materials: [https://github.com/bu-rcs/bu-rcs.github.io/tree/main/Bootcamp](https://github.com/bu-rcs/bu-rcs.github.io/tree/main/Bootcamp)\n",
    "\n",
    "# Python Part 2:  Data Processing and Handling\n",
    "\n",
    "In this part of the tutorial we'll focus on the use of the Pandas library.  Its home on the WWW is:\n",
    "https://pandas.pydata.org/docs/\n",
    "\n",
    "To quote [Wikipedia](https://en.wikipedia.org/wiki/Pandas_(software)):\n",
    "> pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series. \n",
    "\n",
    "Pandas is the most popular tool for high-level inspection and manipulation of data sets like the one we're working with.  First we'll import pandas and label it *pd* for short.  In addition we'll load a few other handy libraries.  \n",
    "\n",
    "* Numpy is a library focused on efficient handling of multi-dimensional numeric data. It underlies most data science libraries in Python, including Pandas. https://numpy.org/ \n",
    "* Scipy is a companion to Numpy that offers a vast array of functions for working with numeric data.  It includes numeric optimization, regression, statistics, image processing, signal processing, and more. https://www.scipy.org/\n",
    "* matplotlib and seaborn are plotting libraries. See https://matplotlib.org/ and https://python-graph-gallery.com/seaborn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a python package that deals mostly with :\n",
    "- **Series**  (1d homogeneous array)\n",
    "- **DataFrame** (2d labeled heterogeneous array - like a table of data from a CSV file)\n",
    "- **Panel** (general 3d array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas *Series* is one-dimentional labeled array containing data of the **same** type (integers, strings, floating point numbers, Python objects, etc. ). The axis labels are often referred to as *index*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of creating Pandas series.  The values are supplied as a list of integers :\n",
    "s1 = pd.Series( [-3,-1,1,3,5] )\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not pass any index, so by default, it assigned the indices (the left hand column) ranging from 0 to len(data)-1\n",
    "\n",
    "The default data type (\"dtype\") is 64-bit integers. Try changing a number to a floating point (i.e. -3.0), what happens to the type?  What if you change one to a string?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View index values\n",
    "print(s1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pandas series with index.  \n",
    "rng = np.random.default_rng() # Get a random number generator\n",
    "# Pull 5  integers in the range from 0-9 from the rng\n",
    "s2 = pd.Series(rng.integers(0,10,10), index=['a', 'b', 'c', 'd', 'e','f','g','h','i','j'] )\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View index values\n",
    "print(s2.index)\n",
    "# Note the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series from dictionary. The keys become the index labels.\n",
    "data = {'pi': 3.1415, 'e': 2.71828}  # dictionary\n",
    "print(data)\n",
    "s3 = pd.Series ( data )\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering the elements\n",
    "s4 = pd.Series ( data, index = ['e', 'pi', 'tau'])\n",
    "print(s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAN (non a number) - is used to specify a missing value in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind ourselves of what s1 is:\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The series elements can be accessed using indices like Python lists\n",
    "s1[:2] # First 2 elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( s1[ [2,1,0]])  # Elements out of order - provide the indices as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series can be used as a numpy ndarray. \n",
    "# The ndarray is the basic data type in the numpy library.  The Pandas Series uses the numpy ndarray to store its data:\n",
    "print(\"Median:\" , s2.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What functions come with a Pandas Series?\n",
    "dir(s2) # this is a long list!\n",
    "# Remember: check the help system to see what functions do.  For example, for the sum function:\n",
    "# help(s2.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1[s1 > 0]  # Filter the Series by using a Boolean condition as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What data type do think is returned?\n",
    "filt_s1 = s1[s1 > 0]\n",
    "type(filt_s1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind yourself what s2 is:\n",
    "print(s2)\n",
    "# What's the median value? Use Numpy.\n",
    "print('The median value of s2 is: %s' % np.median(s2))\n",
    "# Now use the Series median.  Same value, 2 ways to get it.\n",
    "print('The median value of s2 is: %s' % s2.median())\n",
    "\n",
    "# numpy functions can be used on series as usual as part of a Boolean condition:\n",
    "s2[s2 > np.median(s2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy vs Pandas\n",
    "\n",
    "Pandas is built on top of Numpy. Functions like s2.median() ultimately calls numpy.median() to do its calculation.  This is not true of all Pandas functions but it is true most of the time. Pandas Series, Dataframes, and Panels are very easy and convenient to use with a high degree of programmer productivity.  This comes at a price - running Pandas functions involves calling a large quantity of behind-the-scenes Python code before the underlying Numpy code is called. Much of Numpy is implemented in compiled C code which is faster than interpreted Python code.\n",
    "\n",
    "When developing expertise with Pandas, keep in mind that higher performance and faster calculations may be possible to achieve by directly calling Numpy functions. For more information on using Numpy, please see the **Numeric Python** tutorial offered by RCS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popular Attributes and Methods:\n",
    "\n",
    "|  Attribute/Method | Description |\n",
    "|-----|-----|\n",
    "| dtype | data type of values in series |\n",
    "| empty | True if series is empty |\n",
    "| size | number of elements |\n",
    "| values | Returns values as ndarray |\n",
    "| head() | First n elements |\n",
    "| tail() | Last n elements |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of your choice and explore it\n",
    "# <your code goes here >\n",
    "mys = pd.Series( rng.random(21))\n",
    "print(mys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mys.head() # Print the first few elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mys.empty # There are various attributes assigned to the Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas *DataFrame* is two-dimensional, size-mutable, heterogeneous tabular data structure with labeled rows and columns ( axes ). It can be thought of a dictionary-like container to store python Series objects.\n",
    "\n",
    "How do you get a DataFrame?  They can be constructed from Python dictionaries, Numpy arrays, read from files, and returned as the result of function calls involving dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a little dataframe from a dictionary.  The dictionary keys become column labels, the dictionary values the column values.\n",
    "# Here the values are provided as a Pandas Series.\n",
    "d =  pd.DataFrame({ 'Name': pd.Series(['Alice','Bob','Chris']), \n",
    "                  'Age': pd.Series([ 21,25,23]) } )\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make another one.\n",
    "# np.array makes a two-row, three-column numpy ndarray:\n",
    "# [['Alice','Bob','Chris'],\n",
    "#  [ 21,25,23]]\n",
    "# the .T transposes it to 3 rows, 2 columns.\n",
    "# Then that is used to create the dataframe with the column labels.  \n",
    "# Dataframes are column-oriented the way they handle data, as usually done in spreadsheets\n",
    "d2 = pd.DataFrame(np.array([['Alice','Bob','Chris'],[ 21,25,23]]).T, columns=['Name','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column. Just use the column name, similar to the Python dictionary:\n",
    "d['height'] = pd.Series([5.2,6.0,5.6])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read our New England demographics csv file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/bu-rcs/bu-rcs.github.io/main/Bootcamp/Data/NE_DemographicsData.csv\")\n",
    "#### This is a bit of cleanup code that will remove the rows that include aggregate values\n",
    "#### per state.  This will be explained later in the tutorial.\n",
    "df.drop(df[df['County'].isnull()].index, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display a few first records\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first 20 records\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 5 records.  Hint: One of the best things about Python is its consist syntax which is generally followed \n",
    "# by libraries like Pandas.\n",
    "# <your code goes here>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We can straightforwardly delete a column using the del command\n",
    "del df['% Severe Housing Cost Burden']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the type of df object\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the type of a column \"% Homeowners\"\n",
    "df['% Homeowners'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the types of all columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the name of one column.\n",
    "df.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List the row labels and the column names\n",
    "df.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of dimensions\n",
    "df.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total number of elements in the Data Frame\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output basic statistics for the numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean for all numeric columns\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the standard deviation (std() method) for all numeric columns\n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate average of the columns in the first 50 rows\n",
    "# <your code goes here>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data slicing and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a column by name \n",
    "df['Population'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract one column again - notice the double brackets\n",
    "df[['Population']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the difference?\n",
    "print( type(df['Population']) )\n",
    "print( type(df[['Population']]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the basic statistics for the 'Life Expectancy' column (used describe() method)\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate how many values in the 'Life Expectancy' column (use count() method)\n",
    "# <your code goes here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average Life Expectancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data using state\n",
    "df_rank = df.groupby('State')\n",
    "df_rank.head(10)\n",
    "# Note this doesn't look any different...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But if we check the type it's clear it's not a regular dataframe\n",
    "type(df_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate mean of all numeric columns for the grouped object\n",
    "df_rank.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need for a new variable, these can be calculate right from the dataframe.\n",
    "df.groupby('State').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean percentage of rural residents per state\n",
    "# First let's see how to add a new column, % Rural\n",
    "df['% Rural'] = df['# Rural'] / df['Population'] * 100\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do the averaging we want to group by state, sum the population and # Rural columns, and then divide them to correctly\n",
    "# compute the % Rural per state. Create an extra dataframe and then modify it with a new column.\n",
    "df_rural = df.groupby('State')[['# Rural','Population']].sum()\n",
    "df_rural['% Rural2'] = df_rural['# Rural'] / df_rural['Population'] * 100\n",
    "df_rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use double brackets Pandas will produce a DataFrame\n",
    "df.groupby('State')[['Population']].mean() # this is mean pop per county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group using 2 variables.  There's only 1 natural grouping in this df, however.\n",
    "df.groupby(['State','% Female'], sort=True)[['Population']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows with longer life expectancies. df_sub is a new dataframe.\n",
    "df_sub = df[ df['Life Expectancy'] > 80]\n",
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data for Maine\n",
    "df_me = df[ df['State'] == 'Maine']\n",
    "df_me.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using filtering, find the mean value of the # Rural per county for Maine\n",
    "# Your code here.  Expand the next cell to see the solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Using filtering, find the mean value of the # Rural per county for Maine\n",
    "df[ df['State'] =='Maine'].mean().round(2)['# Rural']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Removing Extra Rows and Repeat Part 1 Exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows in the dataset have the county name marked as NaN - these are missing in the CSV file and are labeled as \"Not a Number\" values.  These rows contain aggregate values which we want to compute ourselves.\n",
    "\n",
    "Let's remove those from the dataframe and then repeat the calculation done in Part 1 where we found the total population. While plain Python code can be used (as we did in Part 1) the Pandas library makes the calculation quite straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the dataframe\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/bu-rcs/bu-rcs.github.io/main/Bootcamp/Data/NE_DemographicsData.csv\")\n",
    "\n",
    "# drop() is a dataframe function that can be used to remove rows that meet a condition.  \n",
    "# The condition here is that the County is a null value\n",
    "df[df['County'].isnull()].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and print the index values which are what we need for the drop.\n",
    "df[df['County'].isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use the drop() function.  Give it the index of the rows to drop.\n",
    "# inplace=True means to modify the dataframe, not return a new one. \n",
    "df.drop(df[df['County'].isnull()].index, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now look for anything with a null County\n",
    "df[df['County'].isnull()].index # nothing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe is shorter:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the part 1 exercise...group the data by the states and sum the\n",
    "# population column.  One line!\n",
    "df.groupby(['State']).sum()[['Population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More ways to select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a subset of rows (based on their position):\n",
    "# Note 1: The location of the first row is 0\n",
    "# Note 2: The last value in the range is not included\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to select both rows and columns we can use method .loc\n",
    "df.loc[10:20,['State', 'County','% Homeowners','Median Household Income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see what we get for our df_sub data frame\n",
    "# Method .loc subset the data frame based on the labels:\n",
    "df_sub.loc[3:8,['Life Expectancy','% Frequent Physical Distress','Median Household Income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Unlike method .loc, method iloc selects rows (and columns) by poistion:\n",
    "df_sub.iloc[3:8, [3,4,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data frame by % Female and create a new data frame\n",
    "df_sorted = df.sort_values(by = '% Female')\n",
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data frame by yrs.service and overwrite the original dataset\n",
    "df.sort_values(by = '% Female', ascending = False, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the original order (by sorting using index, i.e. column 0)\n",
    "df.sort_index(axis=0, ascending = True, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data frame by % Rural (in descending order) and display the first few records of the output (head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data frame using 2 or more columns:\n",
    "df_sorted = df.sort_values(by = ['% Rural', '% Limited Access to Healthy Foods'], ascending = [True,False])\n",
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a larger dataset\n",
    "\n",
    "Let's load a larger dataframe, this one is health data for the entire USA by county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.read_csv('https://raw.githubusercontent.com/bu-rcs/bu-rcs.github.io/main/Bootcamp/Data/USA_HealthData.csv')\n",
    "# Clean out the NaN County rows, as before\n",
    "big_df.drop(big_df[big_df['County'].isnull()].index, inplace=True) \n",
    "print(big_df.shape)\n",
    "print(big_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute different statistics for different columns\n",
    "big_df.agg({'% Fair or Poor Health':['min','mean','max'], '% Drive Alone to Work':['median']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The agg function can apply any function to a column provided the function takes a an array-like input (list, numpy ndarray, etc)\n",
    "# and returns a single value.  Here use the numpy median function,just as an example of how to do it.\n",
    "big_df.agg({'% Fair or Poor Health':[np.median]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of built-in agg functions\n",
    "\n",
    "|Function|Description\n",
    "|-------|--------\n",
    "|mean | Compute mean of groups\n",
    "|sum | Compute sum of group values\n",
    "|size | Compute group sizes\n",
    "|count | Compute count of group\n",
    "|std | Standard deviation of groups\n",
    "|var | Compute variance of groups\n",
    "|sem | Standard error of the mean of groups\n",
    "|describe | Generates descriptive statistics\n",
    "|first |  Compute first of group values\n",
    "|last | Compute last of group values\n",
    "|nth | Take nth value, or a subset if n is a list\n",
    "|min | Compute min of group values\n",
    "|max | Compute max of group values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new column using values from a 2nd dataframe\n",
    "\n",
    "Let's open an extra csv file into a dataframe, and then add a new column to the big_df that assigns the US Census Bureau geographic region to each state.\n",
    "\n",
    "![US Census Regions](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Census_Regions_and_Division_of_the_United_States.svg/786px-Census_Regions_and_Division_of_the_United_States.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = pd.read_csv('https://raw.githubusercontent.com/bu-rcs/bu-rcs.github.io/main/Bootcamp/Data/us_states_census_regions.csv')\n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this column to the big_df.  The result will be a new dataframe.  Merge them by matching on the State column in each df.\n",
    "merged = pd.merge(left=big_df, right=reg_df, left_on='State', right_on='State')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And as before we can now groupby with the new column and see who drives the furthest to work by themselves.\n",
    "merged.groupby('Region')[['% Long Commute - Drives Alone']].mean().sort_values(by=['% Long Commute - Drives Alone'],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
